{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from MNISTClassifier import*\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../../datasets/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../../datasets/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=True)\n",
    "\n",
    "testset = np.load(\"sample_test_set_data.npy\")\n",
    "testset_labels = np.load(\"sample_test_set_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------model_1----------------------\n",
      "Params:[4, 2]\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304732\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.934361\n",
      "\n",
      "Test set: Avg. loss: 1.8736, Accuracy: 2253/10000 (23%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.894111\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.690367\n",
      "\n",
      "Test set: Avg. loss: 1.7377, Accuracy: 3035/10000 (30%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.705384\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.627140\n",
      "\n",
      "Test set: Avg. loss: 1.6482, Accuracy: 3265/10000 (33%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 81.2569, Accuracy: 15/50 (30%)\n",
      "\n",
      "---------------------model_2----------------------\n",
      "Params:[2, 1]\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.405226\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.037874\n",
      "\n",
      "Test set: Avg. loss: 1.8831, Accuracy: 2440/10000 (24%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.849847\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.777777\n",
      "\n",
      "Test set: Avg. loss: 1.7148, Accuracy: 3386/10000 (34%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.653205\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.685167\n",
      "\n",
      "Test set: Avg. loss: 1.6372, Accuracy: 3382/10000 (34%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 80.9982, Accuracy: 17/50 (34%)\n",
      "\n",
      "---------------------model_3----------------------\n",
      "Params:[8, 4]\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.291617\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.961756\n",
      "\n",
      "Test set: Avg. loss: 0.5439, Accuracy: 8363/10000 (84%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.504421\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.732315\n",
      "\n",
      "Test set: Avg. loss: 0.4608, Accuracy: 8686/10000 (87%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.502158\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.269136\n",
      "\n",
      "Test set: Avg. loss: 0.4182, Accuracy: 8795/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 33.5780, Accuracy: 39/50 (78%)\n",
      "\n",
      "---------------------model_4----------------------\n",
      "Params:[16, 8]\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.288222\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.316749\n",
      "\n",
      "Test set: Avg. loss: 0.3570, Accuracy: 8949/10000 (89%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.502093\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.246300\n",
      "\n",
      "Test set: Avg. loss: 0.2915, Accuracy: 9120/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.329192\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.337520\n",
      "\n",
      "Test set: Avg. loss: 0.2492, Accuracy: 9267/10000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 21.9500, Accuracy: 42/50 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['model_1', 'model_2', 'model_3', 'model_4']\n",
    "model_params = [[4,2], [2,1], [8,4], [16,8]]\n",
    "\n",
    "for model_name, model_param in zip(model_names, model_params):\n",
    "    \n",
    "    print(\"---------------------{}----------------------\".format(model_name))\n",
    "    \n",
    "    print(\"Params:{}\".format(model_param))\n",
    "\n",
    "    network = Net(model_param)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "\n",
    "    if not os.path.exists('results/{}'.format(model_name)):\n",
    "        os.makedirs('results/{}'.format(model_name))\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train(epoch, network.cuda(), optimizer, model_name, train_loader)\n",
    "        test(network.cuda(), test_loader)\n",
    "\n",
    "    test_model = load_model(model_name)\n",
    "    test_sample(test_model.cuda(), testset, testset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------model_1----------------------\n",
      "Params:[4, 2]\n",
      "\n",
      "Test set: Avg. loss: 59.8022, Accuracy: 30/50 (60%)\n",
      "\n",
      "---------------------model_2----------------------\n",
      "Params:[2, 1]\n",
      "\n",
      "Test set: Avg. loss: 80.9982, Accuracy: 17/50 (34%)\n",
      "\n",
      "---------------------model_3----------------------\n",
      "Params:[8, 4]\n",
      "\n",
      "Test set: Avg. loss: 33.5780, Accuracy: 39/50 (78%)\n",
      "\n",
      "---------------------model_4----------------------\n",
      "Params:[16, 8]\n",
      "\n",
      "Test set: Avg. loss: 21.9500, Accuracy: 42/50 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#THis is how models should be used outside the training environment\n",
    "\n",
    "model_names = ['model_1', 'model_2', 'model_3', 'model_4']\n",
    "model_params = [[4,2], [2,1], [8,4], [16,8]]\n",
    "\n",
    "for model_name, model_param in zip(model_names, model_params):\n",
    "    \n",
    "    print(\"---------------------{}----------------------\".format(model_name))\n",
    "    \n",
    "    print(\"Params:{}\".format(model_param))\n",
    "\n",
    "    test_model = load_model(model_name)\n",
    "    losses, sim_log = test_sample(test_model.cuda(), testset, testset_labels)\n",
    "#Losses are numerical losses per sample. Sim log is a log of successes and failures.\n",
    "#Both metrics can be used to reward the adverserial for its decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1, 1, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
